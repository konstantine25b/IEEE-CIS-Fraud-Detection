{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14242,"databundleVersionId":568274,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:06:53.108701Z","iopub.execute_input":"2025-04-20T12:06:53.109097Z","iopub.status.idle":"2025-04-20T12:06:54.275262Z","shell.execute_reply.started":"2025-04-20T12:06:53.109064Z","shell.execute_reply":"2025-04-20T12:06:54.274104Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/ieee-fraud-detection/sample_submission.csv\n/kaggle/input/ieee-fraud-detection/test_identity.csv\n/kaggle/input/ieee-fraud-detection/train_identity.csv\n/kaggle/input/ieee-fraud-detection/test_transaction.csv\n/kaggle/input/ieee-fraud-detection/train_transaction.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"%pip install mlflow\n%pip install dagshub","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:07:26.554238Z","iopub.execute_input":"2025-04-20T12:07:26.555438Z","iopub.status.idle":"2025-04-20T12:07:46.528726Z","shell.execute_reply.started":"2025-04-20T12:07:26.555378Z","shell.execute_reply":"2025-04-20T12:07:46.527359Z"}},"outputs":[{"name":"stdout","text":"Collecting mlflow\n  Downloading mlflow-2.21.3-py3-none-any.whl.metadata (30 kB)\nCollecting mlflow-skinny==2.21.3 (from mlflow)\n  Downloading mlflow_skinny-2.21.3-py3-none-any.whl.metadata (31 kB)\nRequirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.0)\nRequirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.6)\nRequirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.15.2)\nRequirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (7.1.0)\nCollecting graphene<4 (from mlflow)\n  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\nCollecting gunicorn<24 (from mlflow)\n  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\nRequirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.7)\nRequirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.7.5)\nRequirement already satisfied: numpy<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.26.4)\nRequirement already satisfied: pandas<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.2.3)\nRequirement already satisfied: pyarrow<20,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (19.0.1)\nRequirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.2.2)\nRequirement already satisfied: scipy<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.15.2)\nRequirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.38)\nRequirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (5.5.2)\nRequirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (8.1.8)\nRequirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (3.1.1)\nCollecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.21.3->mlflow)\n  Downloading databricks_sdk-0.50.0-py3-none-any.whl.metadata (38 kB)\nCollecting fastapi<1 (from mlflow-skinny==2.21.3->mlflow)\n  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (3.1.44)\nRequirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (8.6.1)\nRequirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (1.16.0)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (1.16.0)\nRequirement already satisfied: packaging<25 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (24.2)\nRequirement already satisfied: protobuf<6,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (3.20.3)\nRequirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (2.11.3)\nRequirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (6.0.2)\nRequirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (2.32.3)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (0.5.3)\nRequirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (4.13.1)\nCollecting uvicorn<1 (from mlflow-skinny==2.21.3->mlflow)\n  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.9)\nRequirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker<8,>=4.0.0->mlflow) (2.3.0)\nRequirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.3)\nRequirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (2.2.0)\nRequirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (1.9.0)\nCollecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\nCollecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (2.9.0.post0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (11.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (3.2.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\nRequirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.3->mlflow) (2.27.0)\nCollecting starlette<0.47.0,>=0.40.0 (from fastapi<1->mlflow-skinny==2.21.3->mlflow)\n  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.21.3->mlflow) (4.0.12)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.21.3->mlflow) (3.21.0)\nRequirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.21.3->mlflow) (1.2.18)\nRequirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.21.3->mlflow) (75.1.0)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.37b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.21.3->mlflow) (0.37b0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.21.3->mlflow) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.21.3->mlflow) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.21.3->mlflow) (0.4.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.21.3->mlflow) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.21.3->mlflow) (3.10)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.21.3->mlflow) (2025.1.31)\nRequirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn<1->mlflow-skinny==2.21.3->mlflow) (0.14.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3->mlflow) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3->mlflow) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3->mlflow) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3->mlflow) (2024.2.0)\nRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.21.3->mlflow) (1.17.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.21.3->mlflow) (5.0.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.3->mlflow) (0.4.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.3->mlflow) (4.9)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3->mlflow) (2024.2.0)\nRequirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.21.3->mlflow) (3.7.1)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.21.3->mlflow) (1.3.1)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.3->mlflow) (0.6.1)\nDownloading mlflow-2.21.3-py3-none-any.whl (28.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.2/28.2 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading mlflow_skinny-2.21.3-py3-none-any.whl (6.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading databricks_sdk-0.50.0-py3-none-any.whl (692 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m692.3/692.3 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\nDownloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading starlette-0.46.2-py3-none-any.whl (72 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: uvicorn, gunicorn, graphql-core, starlette, graphql-relay, graphene, fastapi, databricks-sdk, mlflow-skinny, mlflow\nSuccessfully installed databricks-sdk-0.50.0 fastapi-0.115.12 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 mlflow-2.21.3 mlflow-skinny-2.21.3 starlette-0.46.2 uvicorn-0.34.2\nNote: you may need to restart the kernel to use updated packages.\nCollecting dagshub\n  Downloading dagshub-0.5.9-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: PyYAML>=5 in /usr/local/lib/python3.11/dist-packages (from dagshub) (6.0.2)\nCollecting appdirs>=1.4.4 (from dagshub)\n  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\nRequirement already satisfied: click>=8.0.4 in /usr/local/lib/python3.11/dist-packages (from dagshub) (8.1.8)\nRequirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from dagshub) (0.28.1)\nRequirement already satisfied: GitPython>=3.1.29 in /usr/local/lib/python3.11/dist-packages (from dagshub) (3.1.44)\nRequirement already satisfied: rich>=13.1.0 in /usr/local/lib/python3.11/dist-packages (from dagshub) (14.0.0)\nCollecting dacite~=1.6.0 (from dagshub)\n  Downloading dacite-1.6.0-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: tenacity>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from dagshub) (9.0.0)\nCollecting gql[requests] (from dagshub)\n  Downloading gql-3.5.2-py2.py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from dagshub) (0.6.7)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from dagshub) (2.2.3)\nCollecting treelib>=1.6.4 (from dagshub)\n  Downloading treelib-1.7.1-py3-none-any.whl.metadata (1.4 kB)\nCollecting pathvalidate>=3.0.0 (from dagshub)\n  Downloading pathvalidate-3.2.3-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from dagshub) (2.9.0.post0)\nRequirement already satisfied: boto3 in /usr/local/lib/python3.11/dist-packages (from dagshub) (1.37.29)\nRequirement already satisfied: semver in /usr/local/lib/python3.11/dist-packages (from dagshub) (3.0.4)\nCollecting dagshub-annotation-converter>=0.1.5 (from dagshub)\n  Downloading dagshub_annotation_converter-0.1.9-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from dagshub-annotation-converter>=0.1.5->dagshub) (5.3.1)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from dagshub-annotation-converter>=0.1.5->dagshub) (11.1.0)\nRequirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from dagshub-annotation-converter>=0.1.5->dagshub) (2.11.3)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from dagshub-annotation-converter>=0.1.5->dagshub) (4.13.1)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from GitPython>=3.1.29->dagshub) (4.0.12)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (3.7.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (1.0.7)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (3.10)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->dagshub) (0.14.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.1.0->dagshub) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.1.0->dagshub) (2.19.1)\nRequirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from treelib>=1.6.4->dagshub) (1.17.0)\nRequirement already satisfied: botocore<1.38.0,>=1.37.29 in /usr/local/lib/python3.11/dist-packages (from boto3->dagshub) (1.37.29)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3->dagshub) (1.0.1)\nRequirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from boto3->dagshub) (0.11.4)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->dagshub) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->dagshub) (0.9.0)\nCollecting graphql-core<3.2.5,>=3.2 (from gql[requests]->dagshub)\n  Downloading graphql_core-3.2.4-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: yarl<2.0,>=1.6 in /usr/local/lib/python3.11/dist-packages (from gql[requests]->dagshub) (1.19.0)\nCollecting backoff<3.0,>=1.11.1 (from gql[requests]->dagshub)\n  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: requests<3,>=2.26 in /usr/local/lib/python3.11/dist-packages (from gql[requests]->dagshub) (2.32.3)\nRequirement already satisfied: requests-toolbelt<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gql[requests]->dagshub) (1.0.0)\nRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->dagshub) (1.26.4)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->dagshub) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->dagshub) (2025.2)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.23.0->dagshub) (1.3.1)\nRequirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore<1.38.0,>=1.37.29->boto3->dagshub) (2.3.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->GitPython>=3.1.29->dagshub) (5.0.2)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->dagshub) (0.1.2)\nRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->dagshub) (24.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->dagshub) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->dagshub) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->dagshub) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->dagshub) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->dagshub) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->dagshub) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->dagshub-annotation-converter>=0.1.5->dagshub) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->dagshub-annotation-converter>=0.1.5->dagshub) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->dagshub-annotation-converter>=0.1.5->dagshub) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.26->gql[requests]->dagshub) (3.4.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->dagshub) (1.0.0)\nRequirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.6->gql[requests]->dagshub) (6.2.0)\nRequirement already satisfied: propcache>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.6->gql[requests]->dagshub) (0.3.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas->dagshub) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas->dagshub) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->pandas->dagshub) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->pandas->dagshub) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->pandas->dagshub) (2024.2.0)\nDownloading dagshub-0.5.9-py3-none-any.whl (260 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.1/260.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\nDownloading dacite-1.6.0-py3-none-any.whl (12 kB)\nDownloading dagshub_annotation_converter-0.1.9-py3-none-any.whl (33 kB)\nDownloading pathvalidate-3.2.3-py3-none-any.whl (24 kB)\nDownloading treelib-1.7.1-py3-none-any.whl (19 kB)\nDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\nDownloading graphql_core-3.2.4-py3-none-any.whl (203 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gql-3.5.2-py2.py3-none-any.whl (74 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: appdirs, treelib, pathvalidate, graphql-core, dacite, backoff, gql, dagshub-annotation-converter, dagshub\n  Attempting uninstall: graphql-core\n    Found existing installation: graphql-core 3.2.6\n    Uninstalling graphql-core-3.2.6:\n      Successfully uninstalled graphql-core-3.2.6\n  Attempting uninstall: dacite\n    Found existing installation: dacite 1.9.2\n    Uninstalling dacite-1.9.2:\n      Successfully uninstalled dacite-1.9.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nydata-profiling 4.16.1 requires dacite>=1.8, but you have dacite 1.6.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed appdirs-1.4.4 backoff-2.2.1 dacite-1.6.0 dagshub-0.5.9 dagshub-annotation-converter-0.1.9 gql-3.5.2 graphql-core-3.2.4 pathvalidate-3.2.3 treelib-1.7.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import mlflow\nimport mlflow.sklearn\nimport time\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score, \n    roc_auc_score, confusion_matrix, classification_report,\n    precision_recall_curve, roc_curve, average_precision_score\n)\nimport dagshub\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:07:57.352661Z","iopub.execute_input":"2025-04-20T12:07:57.353044Z","iopub.status.idle":"2025-04-20T12:08:03.998681Z","shell.execute_reply.started":"2025-04-20T12:07:57.353011Z","shell.execute_reply":"2025-04-20T12:08:03.997096Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"try:\n    # Initialize Dagshub\n    dagshub.init(repo_owner='konstantine25b', repo_name='IEEE-CIS-Fraud-Detection', mlflow=True)\n    print(\"DagsHub initialized successfully.\")\n    mlflow.set_experiment(\"IEEE-CIS-Fraud-Detection_random_forest\")\n    print(f\"MLflow experiment set to: {mlflow.get_experiment_by_name('IEEE-CIS-Fraud-Detection_random_forest').name}\")\n    mlflow_active = True\nexcept Exception as e:\n    print(f\"Could not initialize DagsHub or set MLflow experiment: {e}\")\n    print(\"Proceeding without MLflow tracking.\")\n    mlflow_active = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:08:57.618649Z","iopub.execute_input":"2025-04-20T12:08:57.619062Z","iopub.status.idle":"2025-04-20T12:09:03.073888Z","shell.execute_reply.started":"2025-04-20T12:08:57.619034Z","shell.execute_reply":"2025-04-20T12:09:03.072739Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"                                       \u001b[1m❗❗❗ AUTHORIZATION REQUIRED ❗❗❗\u001b[0m                                        \n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                       <span style=\"font-weight: bold\">❗❗❗ AUTHORIZATION REQUIRED ❗❗❗</span>                                        \n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n\nOpen the following link in your browser to authorize the client:\nhttps://dagshub.com/login/oauth/authorize?state=c3de9ca5-7420-44bb-b767-455d08c3b17e&client_id=32b60ba385aa7cecf24046d8195a71c07dd345d9657977863b52e7748e0f0f28&middleman_request_id=1ba104efbcd5b3dd4df2b6a46ae28dd5614ce6bbb405f4a10175877ad7b9277a\n\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Accessing as konstantine25b\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as konstantine25b\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Initialized MLflow to track repo \u001b[32m\"konstantine25b/IEEE-CIS-Fraud-Detection\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"konstantine25b/IEEE-CIS-Fraud-Detection\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Repository konstantine25b/IEEE-CIS-Fraud-Detection initialized!\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository konstantine25b/IEEE-CIS-Fraud-Detection initialized!\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"DagsHub initialized successfully.\n","output_type":"stream"},{"name":"stderr","text":"2025/04/20 12:09:02 INFO mlflow.tracking.fluent: Experiment with name 'IEEE-CIS-Fraud-Detection_random_forest' does not exist. Creating a new experiment.\n","output_type":"stream"},{"name":"stdout","text":"MLflow experiment set to: IEEE-CIS-Fraud-Detection_random_forest\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"run_name = f\"random_forest_{time.strftime('%Y%m%d_%H%M%S')}\"\nif mlflow_active:\n    mlflow.start_run(run_name=run_name)\n    print(f\"MLflow run started with name: {run_name}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:15:17.863565Z","iopub.execute_input":"2025-04-20T12:15:17.863999Z","iopub.status.idle":"2025-04-20T12:15:18.383000Z","shell.execute_reply.started":"2025-04-20T12:15:17.863971Z","shell.execute_reply":"2025-04-20T12:15:18.381834Z"}},"outputs":[{"name":"stdout","text":"MLflow run started with name: random_forest_20250420_121517\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"print(\"\\n--- Loading Original Data from Kaggle ---\")\ntry:\n    identity_df = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_identity.csv')\n    transaction_df = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv')\n    print(f\"Loaded identity data shape: {identity_df.shape}\")\n    print(f\"Loaded transaction data shape: {transaction_df.shape}\")\nexcept FileNotFoundError:\n    print(\"Error: One or both of the CSV files were not found. Please make sure the file paths are correct.\")\n    if mlflow_active:\n        mlflow.end_run()\n    exit()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:15:24.378233Z","iopub.execute_input":"2025-04-20T12:15:24.379284Z","iopub.status.idle":"2025-04-20T12:15:57.012560Z","shell.execute_reply.started":"2025-04-20T12:15:24.379163Z","shell.execute_reply":"2025-04-20T12:15:57.011211Z"}},"outputs":[{"name":"stdout","text":"\n--- Loading Original Data from Kaggle ---\nLoaded identity data shape: (144233, 41)\nLoaded transaction data shape: (590540, 394)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# Load the preprocessing pipeline from MLflow","metadata":{}},{"cell_type":"code","source":"# Replace with your actual run ID from the preprocessing pipeline\npreprocessing_run_id = '962cdbe1451f4abe864ff349e123e7de'  # Example run ID\ntry:\n    # Load the transaction pipeline model\n    transaction_pipeline = mlflow.sklearn.load_model(f'runs:/{preprocessing_run_id}/transaction_pipeline_model')\n    print(\"Loaded transaction preprocessing pipeline from MLflow.\")\n    \n    # Load the identity pipeline model if it exists\n    try:\n        identity_pipeline = mlflow.sklearn.load_model(f'runs:/{preprocessing_run_id}/identity_pipeline_model')\n        print(\"Loaded identity preprocessing pipeline from MLflow.\")\n        identity_pipeline_exists = True\n    except:\n        print(\"Identity preprocessing pipeline not found. Will only use transaction pipeline.\")\n        identity_pipeline_exists = False\n    \n    # Load the feature selection information\n    try:\n        selected_features = mlflow.artifacts.load_text(f'runs:/{preprocessing_run_id}/selected_features.txt').strip().split('\\n')\n        print(f\"Loaded {len(selected_features)} selected features from MLflow.\")\n    except:\n        print(\"Selected features list not found. Will use all features after preprocessing.\")\n        selected_features = None\nexcept Exception as e:\n    print(f\"Error loading preprocessing pipeline from MLflow: {e}\")\n    print(\"Please ensure you have the correct run ID and the pipeline is properly saved.\")\n    if mlflow_active:\n        mlflow.end_run()\n    exit()\n\n# Split the data\nX_transaction = transaction_df.drop('isFraud', axis=1)\ny_transaction = transaction_df['isFraud']\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X_transaction, y_transaction, test_size=0.2, random_state=42, stratify=y_transaction\n)\nprint(f\"Train set shape: {X_train.shape}\")\nprint(f\"Test set shape: {X_test.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:16:06.203137Z","iopub.execute_input":"2025-04-20T12:16:06.203659Z","iopub.status.idle":"2025-04-20T12:16:23.370262Z","shell.execute_reply.started":"2025-04-20T12:16:06.203632Z","shell.execute_reply":"2025-04-20T12:16:23.369174Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e941ecb6b8a4c88bf043d0bd582ab6c"}},"metadata":{}},{"name":"stdout","text":"Loaded transaction preprocessing pipeline from MLflow.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08f2e9dae9264faf82bf5677558ab168"}},"metadata":{}},{"name":"stdout","text":"Loaded identity preprocessing pipeline from MLflow.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acc15d71526542a08b6f9c6cb7cc69b1"}},"metadata":{}},{"name":"stdout","text":"Loaded 50 selected features from MLflow.\nTrain set shape: (472432, 393)\nTest set shape: (118108, 393)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Get the original feature names before preprocessing\noriginal_feature_names = X_train.columns.tolist()\nprint(f\"Original feature count: {len(original_feature_names)}\")\n\n# Apply the transaction preprocessing pipeline\nprint(\"Applying transaction preprocessing pipeline...\")\nX_train_processed = transaction_pipeline.transform(X_train)\nX_test_processed = transaction_pipeline.transform(X_test)\n\n# Convert to DataFrame with feature names that match the preprocessing pipeline\n# First, use generic names\nfeature_names = [f\"feature_{i}\" for i in range(X_train_processed.shape[1])]\nX_train_final = pd.DataFrame(X_train_processed, columns=feature_names)\nX_test_final = pd.DataFrame(X_test_processed, columns=feature_names)\n\n# Apply feature selection if available\nif selected_features is not None:\n    print(f\"Applying feature selection to keep {len(selected_features)} features...\")\n    \n    # Print some of the selected feature names to understand their format\n    print(f\"Sample selected feature names: {selected_features[:5]}\")\n    \n    # Check if any of the selected features match the original feature names\n    original_matches = [f for f in selected_features if f in original_feature_names]\n    if original_matches:\n        print(f\"Found {len(original_matches)} features that match original feature names.\")\n        \n        # Create a mapping from original feature names to processed feature indices\n        # This is a simplified approach - in reality, the mapping might be more complex\n        feature_mapping = {}\n        for i, feature in enumerate(original_feature_names):\n            if i < len(feature_names):\n                feature_mapping[feature] = feature_names[i]\n        \n        # Map selected features to their corresponding processed features\n        mapped_features = []\n        for feature in selected_features:\n            if feature in feature_mapping:\n                mapped_features.append(feature_mapping[feature])\n        \n        if mapped_features:\n            print(f\"Mapped {len(mapped_features)} selected features to processed features.\")\n            \n            # Apply the selection\n            X_train_final = X_train_final[mapped_features]\n            X_test_final = X_test_final[mapped_features]\n        else:\n            print(\"Could not map any selected features to processed features.\")\n            print(\"Using all processed features.\")\n    else:\n        # If selected features don't match original names, they might be indices or have a different format\n        print(\"Selected features don't match original feature names.\")\n        \n        # Print all selected features to understand their format\n        print(f\"First 5 selected features: {selected_features[:5]}\")\n        print(f\"Last 5 selected features: {selected_features[-5:]}\")\n        \n        # Check what columns are actually available in the processed data\n        print(f\"Available columns in processed data: {X_train_final.columns[:10]}...\")\n        \n        # Extract the indices from the selected feature names\n        feature_indices = []\n        for feature in selected_features:\n            # Try different patterns to extract indices\n            if '_x' in feature or '_y' in feature:\n                # Format like '0_x' or '1_y'\n                parts = feature.split('_')\n                if parts[0].isdigit():\n                    feature_indices.append(int(parts[0]))\n            elif feature.isdigit():\n                # Format like '68'\n                feature_indices.append(int(feature))\n        \n        # Get the available columns in the processed data\n        available_columns = X_train_final.columns.tolist()\n        \n        # Create a new DataFrame with the original feature names\n        X_train_renamed = pd.DataFrame()\n        X_test_renamed = pd.DataFrame()\n        \n        # Map each selected feature to a column in the processed data\n        for i, feature in enumerate(selected_features):\n            if i < len(available_columns):\n                # Use the i-th column from the processed data for the i-th selected feature\n                # Extract as a Series using .iloc to avoid the DataFrame issue\n                X_train_renamed[feature] = X_train_final.iloc[:, i].values\n                X_test_renamed[feature] = X_test_final.iloc[:, i].values\n            else:\n                print(f\"Warning: Not enough columns in processed data for feature {feature}\")\n        \n        # Use the renamed DataFrames\n        X_train_final = X_train_renamed\n        X_test_final = X_test_renamed\n        \n        print(f\"Final train set shape after preprocessing: {X_train_final.shape}\")\n        print(f\"Final test set shape after preprocessing: {X_test_final.shape}\")\n        print(f\"Feature names in final dataset: {X_train_final.columns.tolist()[:5]}...\")\nelse:\n    print(\"No selected features provided. Using all features from the preprocessing pipeline.\")\n\nprint(f\"Final train set shape after preprocessing: {X_train_final.shape}\")\nprint(f\"Final test set shape after preprocessing: {X_test_final.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:16:26.983826Z","iopub.execute_input":"2025-04-20T12:16:26.984618Z","iopub.status.idle":"2025-04-20T12:16:35.020037Z","shell.execute_reply.started":"2025-04-20T12:16:26.984581Z","shell.execute_reply":"2025-04-20T12:16:35.018803Z"}},"outputs":[{"name":"stdout","text":"Original feature count: 393\nApplying transaction preprocessing pipeline...\nApplying feature selection to keep 50 features...\nSample selected feature names: ['0_x', '1_x', '2_x', '3_x', '4_x']\nSelected features don't match original feature names.\nFirst 5 selected features: ['0_x', '1_x', '2_x', '3_x', '4_x']\nLast 5 selected features: ['6_y', '7_y', '8_y', '30_y', '31_y']\nAvailable columns in processed data: Index(['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4',\n       'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9'],\n      dtype='object')...\nFinal train set shape after preprocessing: (472432, 50)\nFinal test set shape after preprocessing: (118108, 50)\nFeature names in final dataset: ['0_x', '1_x', '2_x', '3_x', '4_x']...\nFinal train set shape after preprocessing: (472432, 50)\nFinal test set shape after preprocessing: (118108, 50)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Check for NaN values in the processed data\nprint(\"\\n--- Checking for NaN Values in Processed Data ---\")\ntrain_nan_count = X_train_final.isna().sum().sum()\ntest_nan_count = X_test_final.isna().sum().sum()\n\nprint(f\"Number of NaN values in training data: {train_nan_count}\")\nprint(f\"Number of NaN values in testing data: {test_nan_count}\")\n\nif train_nan_count > 0 or test_nan_count > 0:\n    print(\"WARNING: NaN values found in processed data!\")\n    \n    # Get columns with NaN values\n    train_nan_cols = X_train_final.columns[X_train_final.isna().any()].tolist()\n    test_nan_cols = X_test_final.columns[X_test_final.isna().any()].tolist()\n    \n    if train_nan_cols:\n        print(f\"Training data columns with NaN values: {train_nan_cols}\")\n        print(f\"NaN counts per column: \\n{X_train_final[train_nan_cols].isna().sum()}\")\n    \n    if test_nan_cols:\n        print(f\"Testing data columns with NaN values: {test_nan_cols}\")\n        print(f\"NaN counts per column: \\n{X_test_final[test_nan_cols].isna().sum()}\")\n    \n    # Fill NaN values with median as a quick fix\n    print(\"Filling NaN values with column medians...\")\n    for col in train_nan_cols:\n        median_val = X_train_final[col].median()\n        X_train_final[col] = X_train_final[col].fillna(median_val)\n    \n    for col in test_nan_cols:\n        if col in X_train_final.columns:\n            median_val = X_train_final[col].median()\n        else:\n            median_val = X_test_final[col].median()\n        X_test_final[col] = X_test_final[col].fillna(median_val)\n    \n    # Verify NaN values are gone\n    train_nan_count_after = X_train_final.isna().sum().sum()\n    test_nan_count_after = X_test_final.isna().sum().sum()\n    print(f\"NaN values after filling - training data: {train_nan_count_after}\")\n    print(f\"NaN values after filling - testing data: {test_nan_count_after}\")\nelse:\n    print(\"No NaN values found in processed data. Preprocessing pipeline handled missing values correctly.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:16:41.705467Z","iopub.execute_input":"2025-04-20T12:16:41.705851Z","iopub.status.idle":"2025-04-20T12:16:41.827902Z","shell.execute_reply.started":"2025-04-20T12:16:41.705828Z","shell.execute_reply":"2025-04-20T12:16:41.826826Z"}},"outputs":[{"name":"stdout","text":"\n--- Checking for NaN Values in Processed Data ---\nNumber of NaN values in training data: 0\nNumber of NaN values in testing data: 0\nNo NaN values found in processed data. Preprocessing pipeline handled missing values correctly.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Log preprocessing information\nif mlflow_active:\n    mlflow.log_param(\"original_features\", X_train.shape[1])\n    mlflow.log_param(\"final_features\", X_train_final.shape[1])\n\n# After loading and preprocessing the data, before training the model:\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:17:10.365095Z","iopub.execute_input":"2025-04-20T12:17:10.365480Z","iopub.status.idle":"2025-04-20T12:17:10.661932Z","shell.execute_reply.started":"2025-04-20T12:17:10.365447Z","shell.execute_reply":"2025-04-20T12:17:10.660839Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"# Setting up Cross-Validation and Hyperparameter Tuning","metadata":{}},{"cell_type":"code","source":"pipeline = Pipeline([\n    ('scaler', StandardScaler()),\n    ('classifier', RandomForestClassifier(random_state=42))\n])\n\n# Define a minimal hyperparameter grid for quick training\nparam_grid = {\n    'classifier__n_estimators': [50, 100],  # Number of trees\n    'classifier__max_depth': [10, 15],  # Max depth of trees\n    'classifier__class_weight': ['balanced', 'balanced_subsample']  # Class weight options\n}\n\n# Reduce cross-validation folds\ncv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n\n# Add this code before grid search to sample the training data\n# Sample 10% of the training data for hyperparameter tuning\nsample_size = int(0.1 * len(X_train_final))\nindices = np.random.choice(len(X_train_final), sample_size, replace=False)\nX_train_sample = X_train_final.iloc[indices]\ny_train_sample = y_train.iloc[indices]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:18:30.798767Z","iopub.execute_input":"2025-04-20T12:18:30.799193Z","iopub.status.idle":"2025-04-20T12:18:30.906595Z","shell.execute_reply.started":"2025-04-20T12:18:30.799165Z","shell.execute_reply":"2025-04-20T12:18:30.905620Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"\n# Use the sampled data for grid search\nprint(f\"Using {len(X_train_sample)} samples for hyperparameter tuning...\")\ngrid_search = GridSearchCV(\n    pipeline, \n    param_grid, \n    cv=cv, \n    scoring='average_precision',  # Optimize for average precision\n    verbose=1,\n    n_jobs=-1\n)\ngrid_search.fit(X_train_sample, y_train_sample)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:18:45.498383Z","iopub.execute_input":"2025-04-20T12:18:45.498809Z","iopub.status.idle":"2025-04-20T12:19:41.073191Z","shell.execute_reply.started":"2025-04-20T12:18:45.498782Z","shell.execute_reply":"2025-04-20T12:19:41.071999Z"}},"outputs":[{"name":"stdout","text":"Using 47243 samples for hyperparameter tuning...\nFitting 3 folds for each of 8 candidates, totalling 24 fits\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=42, shuffle=True),\n             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n                                       ('classifier',\n                                        RandomForestClassifier(random_state=42))]),\n             n_jobs=-1,\n             param_grid={'classifier__class_weight': ['balanced',\n                                                      'balanced_subsample'],\n                         'classifier__max_depth': [10, 15],\n                         'classifier__n_estimators': [50, 100]},\n             scoring='average_precision', verbose=1)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=42, shuffle=True),\n             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                                       (&#x27;classifier&#x27;,\n                                        RandomForestClassifier(random_state=42))]),\n             n_jobs=-1,\n             param_grid={&#x27;classifier__class_weight&#x27;: [&#x27;balanced&#x27;,\n                                                      &#x27;balanced_subsample&#x27;],\n                         &#x27;classifier__max_depth&#x27;: [10, 15],\n                         &#x27;classifier__n_estimators&#x27;: [50, 100]},\n             scoring=&#x27;average_precision&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=42, shuffle=True),\n             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                                       (&#x27;classifier&#x27;,\n                                        RandomForestClassifier(random_state=42))]),\n             n_jobs=-1,\n             param_grid={&#x27;classifier__class_weight&#x27;: [&#x27;balanced&#x27;,\n                                                      &#x27;balanced_subsample&#x27;],\n                         &#x27;classifier__max_depth&#x27;: [10, 15],\n                         &#x27;classifier__n_estimators&#x27;: [50, 100]},\n             scoring=&#x27;average_precision&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                (&#x27;classifier&#x27;, RandomForestClassifier(random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"# After finding best parameters, train final model on full dataset\nprint(\"Training final model with best parameters on full dataset...\")\nbest_params = grid_search.best_params_\nfinal_model = Pipeline([\n    ('scaler', StandardScaler()),\n    ('classifier', RandomForestClassifier(\n        n_estimators=best_params['classifier__n_estimators'],\n        max_depth=best_params['classifier__max_depth'],\n        class_weight=best_params['classifier__class_weight'],\n        random_state=42,\n        n_jobs=-1  # Use all cores for training the final model\n    ))\n])\nfinal_model.fit(X_train_final, y_train)\nmodel = final_model  # Use this for predictions\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:19:47.064560Z","iopub.execute_input":"2025-04-20T12:19:47.064974Z","iopub.status.idle":"2025-04-20T12:21:03.846823Z","shell.execute_reply.started":"2025-04-20T12:19:47.064940Z","shell.execute_reply":"2025-04-20T12:21:03.845668Z"}},"outputs":[{"name":"stdout","text":"Training final model with best parameters on full dataset...\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# Log best parameters and cross-validation scores\nif mlflow_active:\n    mlflow.log_params(best_params)\n    mlflow.log_metric(\"best_cv_score\", grid_search.best_score_)\n    \n    # Log all CV results\n    cv_results = pd.DataFrame(grid_search.cv_results_)\n    mlflow.log_text(cv_results.to_string(), \"cv_results.txt\")\n\n# Evaluate the model\nprint(\"\\n--- Evaluating Model Performance ---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:23:37.343402Z","iopub.execute_input":"2025-04-20T12:23:37.343931Z","iopub.status.idle":"2025-04-20T12:23:38.055980Z","shell.execute_reply.started":"2025-04-20T12:23:37.343899Z","shell.execute_reply":"2025-04-20T12:23:38.054962Z"}},"outputs":[{"name":"stdout","text":"\n--- Evaluating Model Performance ---\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Make predictions\ny_pred = model.predict(X_test_final)\ny_pred_proba = model.predict_proba(X_test_final)[:, 1]\n\n# Calculate metrics\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\nroc_auc = roc_auc_score(y_test, y_pred_proba)\navg_precision = average_precision_score(y_test, y_pred_proba)\n\n# Print metrics\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")\nprint(f\"ROC AUC: {roc_auc:.4f}\")\nprint(f\"Average Precision: {avg_precision:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:23:45.767722Z","iopub.execute_input":"2025-04-20T12:23:45.768064Z","iopub.status.idle":"2025-04-20T12:23:48.385513Z","shell.execute_reply.started":"2025-04-20T12:23:45.768040Z","shell.execute_reply":"2025-04-20T12:23:48.384249Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.9376\nPrecision: 0.3236\nRecall: 0.7191\nF1 Score: 0.4463\nROC AUC: 0.9245\nAverage Precision: 0.6065\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# Log metrics\nif mlflow_active:\n    mlflow.log_metric(\"accuracy\", accuracy)\n    mlflow.log_metric(\"precision\", precision)\n    mlflow.log_metric(\"recall\", recall)\n    mlflow.log_metric(\"f1\", f1)\n    mlflow.log_metric(\"roc_auc\", roc_auc)\n    mlflow.log_metric(\"avg_precision\", avg_precision)\n\n# Print classification report\nprint(\"\\nClassification Report:\")\nreport = classification_report(y_test, y_pred)\nprint(report)\n\n# Log classification report\nif mlflow_active:\n    mlflow.log_text(report, \"classification_report.txt\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:23:56.108751Z","iopub.execute_input":"2025-04-20T12:23:56.109129Z","iopub.status.idle":"2025-04-20T12:23:57.311661Z","shell.execute_reply.started":"2025-04-20T12:23:56.109104Z","shell.execute_reply":"2025-04-20T12:23:57.310354Z"}},"outputs":[{"name":"stdout","text":"\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.99      0.95      0.97    113975\n           1       0.32      0.72      0.45      4133\n\n    accuracy                           0.94    118108\n   macro avg       0.66      0.83      0.71    118108\nweighted avg       0.97      0.94      0.95    118108\n\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# Log NaN check results\nif mlflow_active:\n    mlflow.log_param(\"train_nan_count_before\", train_nan_count)\n    mlflow.log_param(\"test_nan_count_before\", test_nan_count)\n    if train_nan_count > 0 or test_nan_count > 0:\n        mlflow.log_param(\"train_nan_count_after\", train_nan_count_after)\n        mlflow.log_param(\"test_nan_count_after\", test_nan_count_after)\n\n# End MLflow run\nif mlflow_active:\n    mlflow.end_run()\n    print(\"MLflow run completed and artifacts logged.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:23:59.410153Z","iopub.execute_input":"2025-04-20T12:23:59.410579Z","iopub.status.idle":"2025-04-20T12:23:59.955595Z","shell.execute_reply.started":"2025-04-20T12:23:59.410552Z","shell.execute_reply":"2025-04-20T12:23:59.954173Z"}},"outputs":[{"name":"stdout","text":"🏃 View run random_forest_20250420_121517 at: https://dagshub.com/konstantine25b/IEEE-CIS-Fraud-Detection.mlflow/#/experiments/4/runs/90ea34d328ae4a9eaeb7eae0d00335e3\n🧪 View experiment at: https://dagshub.com/konstantine25b/IEEE-CIS-Fraud-Detection.mlflow/#/experiments/4\nMLflow run completed and artifacts logged.\n","output_type":"stream"}],"execution_count":22}]}