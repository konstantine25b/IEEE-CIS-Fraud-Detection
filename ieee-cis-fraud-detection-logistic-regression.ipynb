{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14242,"databundleVersionId":568274,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:21:09.009003Z","iopub.execute_input":"2025-04-19T17:21:09.009343Z","iopub.status.idle":"2025-04-19T17:21:09.016750Z","shell.execute_reply.started":"2025-04-19T17:21:09.009315Z","shell.execute_reply":"2025-04-19T17:21:09.015589Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"try:\n    identity_df = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_identity.csv')\n    transaction_df = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv')\nexcept FileNotFoundError:\n    print(\"Error: One or both of the CSV files were not found. Please make sure the file paths are correct.\")\n    #  To prevent the rest of the code from running and causing errors.\n    exit()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:21:09.018364Z","iopub.execute_input":"2025-04-19T17:21:09.018719Z","iopub.status.idle":"2025-04-19T17:21:31.204454Z","shell.execute_reply.started":"2025-04-19T17:21:09.018682Z","shell.execute_reply":"2025-04-19T17:21:31.203330Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%pip install mlflow\n%pip install dagshub","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:21:31.206097Z","iopub.execute_input":"2025-04-19T17:21:31.206885Z","iopub.status.idle":"2025-04-19T17:21:39.501126Z","shell.execute_reply.started":"2025-04-19T17:21:31.206851Z","shell.execute_reply":"2025-04-19T17:21:39.499836Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import mlflow\nimport mlflow.sklearn\nimport time\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score, \n    roc_auc_score, confusion_matrix, classification_report,\n    precision_recall_curve, roc_curve, average_precision_score\n)\n\nimport dagshub\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:21:39.502436Z","iopub.execute_input":"2025-04-19T17:21:39.502725Z","iopub.status.idle":"2025-04-19T17:21:39.508896Z","shell.execute_reply.started":"2025-04-19T17:21:39.502698Z","shell.execute_reply":"2025-04-19T17:21:39.507815Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize MLflow tracking\ntry:\n    # Initialize Dagshub\n    dagshub.init(repo_owner='konstantine25b', repo_name='IEEE-CIS-Fraud-Detection', mlflow=True)\n    print(\"DagsHub initialized successfully.\")\n    mlflow.set_experiment(\"IEEE-CIS-Fraud-Detection_logistic_regression\")\n    print(f\"MLflow experiment set to: {mlflow.get_experiment_by_name('IEEE-CIS-Fraud-Detection_logistic_regression').name}\")\n    mlflow_active = True\nexcept Exception as e:\n    print(f\"Could not initialize DagsHub or set MLflow experiment: {e}\")\n    print(\"Proceeding without MLflow tracking.\")\n    mlflow_active = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:21:39.510899Z","iopub.execute_input":"2025-04-19T17:21:39.511155Z","iopub.status.idle":"2025-04-19T17:21:46.500664Z","shell.execute_reply.started":"2025-04-19T17:21:39.511135Z","shell.execute_reply":"2025-04-19T17:21:46.499645Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Start MLflow run\nrun_name = f\"logistic_regression_{time.strftime('%Y%m%d_%H%M%S')}\"\nif mlflow_active:\n    mlflow.start_run(run_name=run_name)\n    print(f\"MLflow run started with name: {run_name}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:21:46.501722Z","iopub.execute_input":"2025-04-19T17:21:46.502103Z","iopub.status.idle":"2025-04-19T17:21:46.908390Z","shell.execute_reply.started":"2025-04-19T17:21:46.502071Z","shell.execute_reply":"2025-04-19T17:21:46.907174Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Loaded identity data shape: {identity_df.shape}\")\nprint(f\"Loaded transaction data shape: {transaction_df.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:24:56.208534Z","iopub.execute_input":"2025-04-19T17:24:56.208850Z","iopub.status.idle":"2025-04-19T17:24:56.214122Z","shell.execute_reply.started":"2025-04-19T17:24:56.208823Z","shell.execute_reply":"2025-04-19T17:24:56.213111Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load the preprocessing pipeline from MLflow","metadata":{}},{"cell_type":"code","source":"# Load the preprocessing pipeline from MLflow\nprint(\"\\n--- Loading Preprocessing Pipeline from MLflow ---\")\n# Replace with your actual run ID from the preprocessing pipeline\npreprocessing_run_id = '962cdbe1451f4abe864ff349e123e7de'  # Example run ID\ntry:\n    # Load the transaction pipeline model\n    transaction_pipeline = mlflow.sklearn.load_model(f'runs:/{preprocessing_run_id}/transaction_pipeline_model')\n    print(\"Loaded transaction preprocessing pipeline from MLflow.\")\n    \n    # Load the identity pipeline model if it exists\n    try:\n        identity_pipeline = mlflow.sklearn.load_model(f'runs:/{preprocessing_run_id}/identity_pipeline_model')\n        print(\"Loaded identity preprocessing pipeline from MLflow.\")\n        identity_pipeline_exists = True\n    except:\n        print(\"Identity preprocessing pipeline not found. Will only use transaction pipeline.\")\n        identity_pipeline_exists = False\n    \n    # Load the feature selection information\n    try:\n        selected_features = mlflow.artifacts.load_text(f'runs:/{preprocessing_run_id}/selected_features.txt').strip().split('\\n')\n        print(f\"Loaded {len(selected_features)} selected features from MLflow.\")\n    except:\n        print(\"Selected features list not found. Will use all features after preprocessing.\")\n        selected_features = None\nexcept Exception as e:\n    print(f\"Error loading preprocessing pipeline from MLflow: {e}\")\n    print(\"Please ensure you have the correct run ID and the pipeline is properly saved.\")\n    if mlflow_active:\n        mlflow.end_run()\n    exit()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:21:46.917526Z","iopub.execute_input":"2025-04-19T17:21:46.917841Z","iopub.status.idle":"2025-04-19T17:21:59.984475Z","shell.execute_reply.started":"2025-04-19T17:21:46.917812Z","shell.execute_reply":"2025-04-19T17:21:59.983587Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Apply the preprocessing pipeline\nprint(\"\\n--- Applying Preprocessing Pipeline ---\")\n\n# Split the data\nX_transaction = transaction_df.drop('isFraud', axis=1)\ny_transaction = transaction_df['isFraud']\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X_transaction, y_transaction, test_size=0.2, random_state=42, stratify=y_transaction\n)\nprint(f\"Train set shape: {X_train.shape}\")\nprint(f\"Test set shape: {X_test.shape}\")\n\n# Get the original feature names before preprocessing\noriginal_feature_names = X_train.columns.tolist()\nprint(f\"Original feature count: {len(original_feature_names)}\")\n\n# Apply the transaction preprocessing pipeline\nprint(\"Applying transaction preprocessing pipeline...\")\nX_train_processed = transaction_pipeline.transform(X_train)\nX_test_processed = transaction_pipeline.transform(X_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:21:59.985544Z","iopub.execute_input":"2025-04-19T17:21:59.986076Z","iopub.status.idle":"2025-04-19T17:22:10.312352Z","shell.execute_reply.started":"2025-04-19T17:21:59.986045Z","shell.execute_reply":"2025-04-19T17:22:10.311272Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Convert to DataFrame with feature names that match the preprocessing pipeline\n# First, use generic names\nfeature_names = [f\"feature_{i}\" for i in range(X_train_processed.shape[1])]\nX_train_final = pd.DataFrame(X_train_processed, columns=feature_names)\nX_test_final = pd.DataFrame(X_test_processed, columns=feature_names)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:22:10.313648Z","iopub.execute_input":"2025-04-19T17:22:10.313975Z","iopub.status.idle":"2025-04-19T17:22:10.319371Z","shell.execute_reply.started":"2025-04-19T17:22:10.313951Z","shell.execute_reply":"2025-04-19T17:22:10.318433Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if selected_features is not None:\n    print(f\"Applying feature selection to keep {len(selected_features)} features...\")\n    \n    # Print some of the selected feature names to understand their format\n    print(f\"Sample selected feature names: {selected_features[:5]}\")\n    \n    # Check if any of the selected features match the original feature names\n    original_matches = [f for f in selected_features if f in original_feature_names]\n    if original_matches:\n        print(f\"Found {len(original_matches)} features that match original feature names.\")\n        \n        # Create a mapping from original feature names to processed feature indices\n        # This is a simplified approach - in reality, the mapping might be more complex\n        feature_mapping = {}\n        for i, feature in enumerate(original_feature_names):\n            if i < len(feature_names):\n                feature_mapping[feature] = feature_names[i]\n        \n        # Map selected features to their corresponding processed features\n        mapped_features = []\n        for feature in selected_features:\n            if feature in feature_mapping:\n                mapped_features.append(feature_mapping[feature])\n        \n        if mapped_features:\n            print(f\"Mapped {len(mapped_features)} selected features to processed features.\")\n            \n            # Apply the selection\n            X_train_final = X_train_final[mapped_features]\n            X_test_final = X_test_final[mapped_features]\n        else:\n            print(\"Could not map any selected features to processed features.\")\n            print(\"Using all processed features.\")\n    else:\n        # If selected features don't match original names, they might be indices or have a different format\n        print(\"Selected features don't match original feature names.\")\n        \n        # Print all selected features to understand their format\n        print(f\"First 5 selected features: {selected_features[:5]}\")\n        print(f\"Last 5 selected features: {selected_features[-5:]}\")\n        \n        # Check what columns are actually available in the processed data\n        print(f\"Available columns in processed data: {X_train_final.columns[:10]}...\")\n        \n        # Extract the indices from the selected feature names\n        feature_indices = []\n        for feature in selected_features:\n            # Try different patterns to extract indices\n            if '_x' in feature or '_y' in feature:\n                # Format like '0_x' or '1_y'\n                parts = feature.split('_')\n                if parts[0].isdigit():\n                    feature_indices.append(int(parts[0]))\n            elif feature.isdigit():\n                # Format like '68'\n                feature_indices.append(int(feature))\n        \n        # Get the available columns in the processed data\n        available_columns = X_train_final.columns.tolist()\n        \n        # Create a new DataFrame with the original feature names\n        X_train_renamed = pd.DataFrame()\n        X_test_renamed = pd.DataFrame()\n        \n        # Map each selected feature to a column in the processed data\n        for i, feature in enumerate(selected_features):\n            if i < len(available_columns):\n                # Use the i-th column from the processed data for the i-th selected feature\n                # Extract as a Series using .iloc to avoid the DataFrame issue\n                X_train_renamed[feature] = X_train_final.iloc[:, i].values\n                X_test_renamed[feature] = X_test_final.iloc[:, i].values\n            else:\n                print(f\"Warning: Not enough columns in processed data for feature {feature}\")\n        \n        # Use the renamed DataFrames\n        X_train_final = X_train_renamed\n        X_test_final = X_test_renamed\n        \n        print(f\"Final train set shape after preprocessing: {X_train_final.shape}\")\n        print(f\"Final test set shape after preprocessing: {X_test_final.shape}\")\n        print(f\"Feature names in final dataset: {X_train_final.columns.tolist()[:5]}...\")\nelse:\n    print(\"No selected features provided. Using all features from the preprocessing pipeline.\")\n\nprint(f\"Final train set shape after preprocessing: {X_train_final.shape}\")\nprint(f\"Final test set shape after preprocessing: {X_test_final.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:28:19.215524Z","iopub.execute_input":"2025-04-19T17:28:19.216307Z","iopub.status.idle":"2025-04-19T17:28:19.689284Z","shell.execute_reply.started":"2025-04-19T17:28:19.216277Z","shell.execute_reply":"2025-04-19T17:28:19.688415Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_final.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:29:01.640888Z","iopub.execute_input":"2025-04-19T17:29:01.641184Z","iopub.status.idle":"2025-04-19T17:29:01.647575Z","shell.execute_reply.started":"2025-04-19T17:29:01.641162Z","shell.execute_reply":"2025-04-19T17:29:01.646681Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check for NaN values in the processed data\nprint(\"\\n--- Checking for NaN Values in Processed Data ---\")\ntrain_nan_count = X_train_final.isna().sum().sum()\ntest_nan_count = X_test_final.isna().sum().sum()\n\nprint(f\"Number of NaN values in training data: {train_nan_count}\")\nprint(f\"Number of NaN values in testing data: {test_nan_count}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:29:26.331491Z","iopub.execute_input":"2025-04-19T17:29:26.331840Z","iopub.status.idle":"2025-04-19T17:29:26.449321Z","shell.execute_reply.started":"2025-04-19T17:29:26.331808Z","shell.execute_reply":"2025-04-19T17:29:26.448303Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if train_nan_count > 0 or test_nan_count > 0:\n    print(\"WARNING: NaN values found in processed data!\")\n    \n    # Get columns with NaN values\n    train_nan_cols = X_train_final.columns[X_train_final.isna().any()].tolist()\n    test_nan_cols = X_test_final.columns[X_test_final.isna().any()].tolist()\n    \n    if train_nan_cols:\n        print(f\"Training data columns with NaN values: {train_nan_cols}\")\n        print(f\"NaN counts per column: \\n{X_train_final[train_nan_cols].isna().sum()}\")\n    \n    if test_nan_cols:\n        print(f\"Testing data columns with NaN values: {test_nan_cols}\")\n        print(f\"NaN counts per column: \\n{X_test_final[test_nan_cols].isna().sum()}\")\n    \n    # Fill NaN values with median as a quick fix\n    print(\"Filling NaN values with column medians...\")\n    for col in train_nan_cols:\n        median_val = X_train_final[col].median()\n        X_train_final[col] = X_train_final[col].fillna(median_val)\n    \n    for col in test_nan_cols:\n        if col in X_train_final.columns:\n            median_val = X_train_final[col].median()\n        else:\n            median_val = X_test_final[col].median()\n        X_test_final[col] = X_test_final[col].fillna(median_val)\n    \n    # Verify NaN values are gone\n    train_nan_count_after = X_train_final.isna().sum().sum()\n    test_nan_count_after = X_test_final.isna().sum().sum()\n    print(f\"NaN values after filling - training data: {train_nan_count_after}\")\n    print(f\"NaN values after filling - testing data: {test_nan_count_after}\")\nelse:\n    print(\"No NaN values found in processed data. Preprocessing pipeline handled missing values correctly.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:29:47.209630Z","iopub.execute_input":"2025-04-19T17:29:47.209916Z","iopub.status.idle":"2025-04-19T17:29:47.218258Z","shell.execute_reply.started":"2025-04-19T17:29:47.209896Z","shell.execute_reply":"2025-04-19T17:29:47.217283Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Log preprocessing information\nif mlflow_active:\n    mlflow.log_param(\"original_features\", X_train.shape[1])\n    mlflow.log_param(\"final_features\", X_train_final.shape[1])\n\n# Train Logistic Regression model\nprint(\"\\n--- Training Logistic Regression Model ---\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:29:56.858638Z","iopub.execute_input":"2025-04-19T17:29:56.859494Z","iopub.status.idle":"2025-04-19T17:29:57.018504Z","shell.execute_reply.started":"2025-04-19T17:29:56.859463Z","shell.execute_reply":"2025-04-19T17:29:57.017727Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define hyperparameters\nC_value = 1.0\nmax_iter = 1000\nsolver = 'liblinear'\nclass_weight = 'balanced'\n\n# Log hyperparameters\nif mlflow_active:\n    mlflow.log_param(\"C\", C_value)\n    mlflow.log_param(\"max_iter\", max_iter)\n    mlflow.log_param(\"solver\", solver)\n    mlflow.log_param(\"class_weight\", class_weight)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:30:20.435883Z","iopub.execute_input":"2025-04-19T17:30:20.436558Z","iopub.status.idle":"2025-04-19T17:30:20.699956Z","shell.execute_reply.started":"2025-04-19T17:30:20.436531Z","shell.execute_reply":"2025-04-19T17:30:20.699184Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create and train the model\nmodel = LogisticRegression(\n    C=C_value,\n    max_iter=max_iter,\n    solver=solver,\n    class_weight=class_weight,\n    random_state=42,\n    n_jobs=-1\n)\n\nstart_time = time.time()\nmodel.fit(X_train_final, y_train)\ntraining_time = time.time() - start_time\n\nprint(f\"Model trained in {training_time:.2f} seconds\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:30:32.582847Z","iopub.execute_input":"2025-04-19T17:30:32.583231Z","iopub.status.idle":"2025-04-19T17:31:40.793716Z","shell.execute_reply.started":"2025-04-19T17:30:32.583187Z","shell.execute_reply":"2025-04-19T17:31:40.792585Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Log training time\nif mlflow_active:\n    mlflow.log_metric(\"training_time\", training_time)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:31:51.333102Z","iopub.execute_input":"2025-04-19T17:31:51.333416Z","iopub.status.idle":"2025-04-19T17:31:51.392458Z","shell.execute_reply.started":"2025-04-19T17:31:51.333394Z","shell.execute_reply":"2025-04-19T17:31:51.391475Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate the model\nprint(\"\\n--- Evaluating Model Performance ---\")\n\n# Make predictions\ny_pred = model.predict(X_test_final)\ny_pred_proba = model.predict_proba(X_test_final)[:, 1]\n\n# Calculate metrics\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\nroc_auc = roc_auc_score(y_test, y_pred_proba)\navg_precision = average_precision_score(y_test, y_pred_proba)\n\n# Print metrics\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")\nprint(f\"ROC AUC: {roc_auc:.4f}\")\nprint(f\"Average Precision: {avg_precision:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:32:12.571795Z","iopub.execute_input":"2025-04-19T17:32:12.572300Z","iopub.status.idle":"2025-04-19T17:32:12.853198Z","shell.execute_reply.started":"2025-04-19T17:32:12.572267Z","shell.execute_reply":"2025-04-19T17:32:12.852253Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Log metrics\nif mlflow_active:\n    mlflow.log_metric(\"accuracy\", accuracy)\n    mlflow.log_metric(\"precision\", precision)\n    mlflow.log_metric(\"recall\", recall)\n    mlflow.log_metric(\"f1\", f1)\n    mlflow.log_metric(\"roc_auc\", roc_auc)\n    mlflow.log_metric(\"avg_precision\", avg_precision)\n\n# Print classification report\nprint(\"\\nClassification Report:\")\nreport = classification_report(y_test, y_pred)\nprint(report)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:32:32.753484Z","iopub.execute_input":"2025-04-19T17:32:32.753841Z","iopub.status.idle":"2025-04-19T17:32:33.318876Z","shell.execute_reply.started":"2025-04-19T17:32:32.753817Z","shell.execute_reply":"2025-04-19T17:32:33.317916Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Log classification report\nif mlflow_active:\n    mlflow.log_text(report, \"classification_report.txt\")\n\n# Create and log confusion matrix\ncm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.title('Confusion Matrix')\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\nplt.tight_layout()\ncm_path = \"confusion_matrix.png\"\nplt.savefig(cm_path)\nplt.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:33:03.102441Z","iopub.execute_input":"2025-04-19T17:33:03.103007Z","iopub.status.idle":"2025-04-19T17:33:03.715636Z","shell.execute_reply.started":"2025-04-19T17:33:03.102979Z","shell.execute_reply":"2025-04-19T17:33:03.714695Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create and log ROC curve\nplt.figure(figsize=(8, 6))\nfpr, tpr, _ = roc_curve(y_test, y_pred_proba)\nplt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.4f})')\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend()\nplt.tight_layout()\nroc_path = \"roc_curve.png\"\nplt.savefig(roc_path)\nplt.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:33:12.945850Z","iopub.execute_input":"2025-04-19T17:33:12.946177Z","iopub.status.idle":"2025-04-19T17:33:13.179174Z","shell.execute_reply.started":"2025-04-19T17:33:12.946152Z","shell.execute_reply":"2025-04-19T17:33:13.178379Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create and log Precision-Recall curve\nplt.figure(figsize=(8, 6))\nprecision_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_proba)\nplt.plot(recall_curve, precision_curve, label=f'PR Curve (AP = {avg_precision:.4f})')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-Recall Curve')\nplt.legend()\nplt.tight_layout()\npr_path = \"precision_recall_curve.png\"\nplt.savefig(pr_path)\nplt.close()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:33:22.662928Z","iopub.execute_input":"2025-04-19T17:33:22.663277Z","iopub.status.idle":"2025-04-19T17:33:22.954230Z","shell.execute_reply.started":"2025-04-19T17:33:22.663252Z","shell.execute_reply":"2025-04-19T17:33:22.953254Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Log artifacts\nif mlflow_active:\n    mlflow.log_artifact(cm_path)\n    mlflow.log_artifact(roc_path)\n    mlflow.log_artifact(pr_path)\n    \n    # Log the model\n    mlflow.sklearn.log_model(model, \"logistic_regression_model\")\n    \n    # Log feature coefficients\n    coef_df = pd.DataFrame({\n        'Feature': X_train_final.columns,\n        'Coefficient': model.coef_[0],\n        'Abs_Coefficient': np.abs(model.coef_[0])\n    }).sort_values('Abs_Coefficient', ascending=False)\n    \n    mlflow.log_text(coef_df.to_string(), \"feature_coefficients.txt\")\n    \n    # Create and log feature importance plot\n    plt.figure(figsize=(12, 10))\n    top_n = 20\n    top_coef = coef_df.head(top_n)\n    colors = ['red' if c < 0 else 'green' for c in top_coef['Coefficient']]\n    plt.barh(top_coef['Feature'], top_coef['Abs_Coefficient'], color=colors)\n    plt.title(f'Top {top_n} Feature Coefficients (Red = Negative, Green = Positive)')\n    plt.xlabel('Absolute Coefficient Value')\n    plt.tight_layout()\n    coef_path = \"feature_coefficients.png\"\n    plt.savefig(coef_path)\n    plt.close()\n    \n    mlflow.log_artifact(coef_path)\n\n# Log NaN check results\nif mlflow_active:\n    mlflow.log_param(\"train_nan_count_before\", train_nan_count)\n    mlflow.log_param(\"test_nan_count_before\", test_nan_count)\n    if train_nan_count > 0 or test_nan_count > 0:\n        mlflow.log_param(\"train_nan_count_after\", train_nan_count_after)\n        mlflow.log_param(\"test_nan_count_after\", test_nan_count_after)\n\n# End MLflow run\nif mlflow_active:\n    mlflow.end_run()\n    print(\"MLflow run completed and artifacts logged.\")\n\nprint(\"\\n--- Logistic Regression Training and Evaluation Completed ---\") ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T17:33:34.414449Z","iopub.execute_input":"2025-04-19T17:33:34.414741Z","iopub.status.idle":"2025-04-19T17:33:51.440803Z","shell.execute_reply.started":"2025-04-19T17:33:34.414721Z","shell.execute_reply":"2025-04-19T17:33:51.439824Z"}},"outputs":[],"execution_count":null}]}